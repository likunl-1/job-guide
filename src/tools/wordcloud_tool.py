"""
è¯äº‘ç”Ÿæˆå·¥å…·

ä¸ºå°±ä¸šå¸‚åœºåˆ†æç”Ÿæˆè¯äº‘ï¼Œå±•ç¤ºçƒ­é—¨èŒä½ã€æŠ€èƒ½ã€å…¬å¸ç­‰å…³é”®è¯
"""

import os
import json
import re
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import matplotlib.font_manager as fm
from typing import Optional, List, Dict, Any
from collections import Counter
from langchain.tools import tool

# é…ç½®ä¸­æ–‡å­—ä½“ - ä¼˜å…ˆä½¿ç”¨ç³»ç»Ÿä¸­å·²ç¡®è®¤çš„å­—ä½“æ–‡ä»¶
chinese_font = None

# ä¼˜å…ˆä½¿ç”¨æ–‡æ³‰é©¿å¾®ç±³é»‘ï¼ˆæ”¯æŒä¸­æ–‡ï¼Œæ˜¾ç¤ºæ•ˆæœè¾ƒå¥½ï¼‰
preferred_font_path = '/usr/share/fonts/truetype/wqy/wqy-microhei.ttc'
if os.path.exists(preferred_font_path):
    chinese_font = preferred_font_path
else:
    # å¤‡ç”¨å­—ä½“è·¯å¾„åˆ—è¡¨
    font_paths = [
        '/usr/share/fonts/truetype/wqy/wqy-zenhei.ttc',
        '/usr/share/fonts/truetype/arphic/uming.ttc',
        '/usr/share/fonts/truetype/arphic/ukai.ttc'
    ]
    for font_path in font_paths:
        if os.path.exists(font_path):
            chinese_font = font_path
            break


def extract_keywords(text: str, max_words: int = 100) -> Dict[str, int]:
    """ä»æ–‡æœ¬ä¸­æå–å…³é”®è¯"""
    # ç§»é™¤æ ‡ç‚¹ç¬¦å·å’Œç‰¹æ®Šå­—ç¬¦
    text = re.sub(r'[^\w\s\u4e00-\u9fff]', ' ', text)

    # åˆ†è¯ï¼ˆç®€å•æŒ‰ç©ºæ ¼å’Œå¸¸è§åˆ†éš”ç¬¦ï¼‰
    words = text.split()

    # è¿‡æ»¤æ‰å¤ªçŸ­çš„è¯å’Œå¸¸è§åœç”¨è¯
    stop_words = {'çš„', 'äº†', 'åœ¨', 'æ˜¯', 'å’Œ', 'ä¸', 'æˆ–', 'ä½†', 'ç­‰', 'åŠ', 'è¿™', 'é‚£',
                  'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for'}

    filtered_words = [word for word in words if len(word) > 1 and word not in stop_words]

    # ç»Ÿè®¡è¯é¢‘
    word_freq = Counter(filtered_words)

    # è¿”å›å‰Nä¸ªé«˜é¢‘è¯
    return dict(word_freq.most_common(max_words))


def parse_keyword_text(text: str) -> Dict[str, int]:
    """
    è§£æç”¨æˆ·è¾“å…¥çš„å…³é”®è¯æ–‡æœ¬æ ¼å¼
    æ”¯æŒæ ¼å¼ï¼š
    1. "æ•°æ®åˆ†æ(95)ã€Python(90)ã€SQL(88)"
    2. "æ•°æ®åˆ†æ 95, Python 90, SQL 88"
    3. "æ•°æ®åˆ†æ:95, Python:90, SQL:88"
    """
    word_freq = {}

    # å°è¯•åŒ¹é… "å…³é”®è¯(æƒé‡)" æˆ– "å…³é”®è¯:æƒé‡" æ ¼å¼
    pattern = r'([^\s()ã€,ï¼Œ:ï¼š]+)[\(:ï¼š](\d+)'

    matches = re.findall(pattern, text)
    if matches:
        for keyword, weight in matches:
            keyword = keyword.strip()
            weight = int(weight)
            if keyword and weight > 0:
                word_freq[keyword] = weight
    else:
        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ï¼Œå°è¯•ä½¿ç”¨åŸå§‹æ–‡æœ¬æå–æ–¹æ³•
        return extract_keywords(text)

    return word_freq


def get_sample_keywords(max_words: int = 100) -> Dict[str, int]:
    """è·å–ç¤ºä¾‹å…³é”®è¯æ•°æ®"""
    keywords = [
        ("Python", 100), ("Java", 95), ("JavaScript", 90), ("SQL", 88), ("React", 85),
        ("Vue", 82), ("æ•°æ®åˆ†æ", 95), ("æœºå™¨å­¦ä¹ ", 80), ("æ·±åº¦å­¦ä¹ ", 70), ("ç®—æ³•", 75),
        ("åç«¯å¼€å‘", 85), ("å‰ç«¯å¼€å‘", 88), ("å…¨æ ˆå¼€å‘", 75), ("ç§»åŠ¨å¼€å‘", 70),
        ("äº‘è®¡ç®—", 65), ("å¤§æ•°æ®", 78), ("äººå·¥æ™ºèƒ½", 72), ("åŒºå—é“¾", 55), ("ç‰©è”ç½‘", 60),
        ("DevOps", 68), ("å¾®æœåŠ¡", 75), ("Docker", 70), ("Kubernetes", 65), ("Git", 80),
        ("Linux", 78), ("MySQL", 82), ("PostgreSQL", 70), ("MongoDB", 65), ("Redis", 75),
        ("æµ‹è¯•", 70), ("è‡ªåŠ¨åŒ–æµ‹è¯•", 65), ("æ€§èƒ½ä¼˜åŒ–", 72), ("ç³»ç»Ÿè®¾è®¡", 78), ("æ¶æ„", 75),
        ("ç½‘ç»œå®‰å…¨", 60), ("æ•°æ®å®‰å…¨", 58), ("äº§å“ç»ç†", 75), ("UIè®¾è®¡", 68), ("UXè®¾è®¡", 65),
        ("é¡¹ç›®ç®¡ç†", 72), ("æ•æ·å¼€å‘", 70), ("Scrum", 65), ("æ•°æ®åˆ†æ", 95), ("æ•°æ®æŒ–æ˜", 70),
        ("è‡ªç„¶è¯­è¨€å¤„ç†", 60), ("è®¡ç®—æœºè§†è§‰", 58), ("æ¨èç³»ç»Ÿ", 62), ("æ•°æ®å¯è§†åŒ–", 68),
        ("TensorFlow", 55), ("PyTorch", 60), ("Keras", 50), ("Flask", 65), ("Django", 70),
        ("Spring", 75), ("SpringBoot", 72), ("MyBatis", 65), ("Vue.js", 80), ("Angular", 55),
        ("TypeScript", 70), ("Node.js", 68), ("Go", 60), ("Rust", 50), ("C++", 65),
        ("C#", 62), ("PHP", 55), ("Ruby", 50), ("Swift", 52), ("Kotlin", 55),
        ("Flutter", 58), ("ReactNative", 60), ("Electron", 55), ("Web3", 45), ("Metaverse", 40),
        ("Unity", 50), ("Unreal", 48), ("æ¸¸æˆå¼€å‘", 65), ("VR", 52), ("AR", 50),
        ("ä½ä»£ç ", 58), ("æ— ä»£ç ", 55), ("SaaS", 62), ("PaaS", 58), ("IaaS", 55),
        ("Serverless", 60), ("FaaS", 55), ("è¾¹ç¼˜è®¡ç®—", 55), ("5G", 58), ("IoT", 60)
    ]

    return dict(keywords[:max_words])


def format_wordcloud_result(word_freq: Dict[str, int], filepath: str, title: str) -> str:
    """æ ¼å¼åŒ–è¯äº‘ç»“æœ"""
    # æŒ‰æƒé‡æ’åº
    sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)

    result = f"""
## â˜ï¸ è¯äº‘å›¾å·²ç”Ÿæˆ

**æ ‡é¢˜**ï¼š{title}
**ä¿å­˜è·¯å¾„**ï¼š{filepath}
**è¯æ±‡æ•°é‡**ï¼š{len(word_freq)}

---

### ğŸ”¥ TOP 20 çƒ­é—¨è¯æ±‡

| æ’å | å…³é”®è¯ | æƒé‡ | çƒ­åº¦ |
|------|--------|------|------|
"""

    for i, (word, weight) in enumerate(sorted_words[:20], 1):
        # è®¡ç®—çƒ­åº¦ç­‰çº§
        if weight >= 90:
            emoji = "ğŸ”¥ğŸ”¥ğŸ”¥"
            level = "æçƒ­"
        elif weight >= 80:
            emoji = "ğŸ”¥ğŸ”¥"
            level = "å¾ˆçƒ­"
        elif weight >= 70:
            emoji = "ğŸ”¥"
            level = "çƒ­é—¨"
        elif weight >= 60:
            emoji = "â­"
            level = "æµè¡Œ"
        else:
            emoji = "ğŸ“Œ"
            level = "å¸¸è§"

        result += f"| {i} | **{word}** | {weight} | {emoji} {level} |\n"

    # æ·»åŠ åˆ†æ
    result += f"""
---

### ğŸ“Š æ•°æ®åˆ†æ

**æ•´ä½“ç‰¹å¾**ï¼š
- æœ€çƒ­é—¨è¯æ±‡ï¼š**{sorted_words[0][0]}**ï¼ˆæƒé‡ï¼š{sorted_words[0][1]}ï¼‰
- å‰10åè¯æ±‡å¹³å‡æƒé‡ï¼š{sum(w for _, w in sorted_words[:10]) / 10:.1f}
- æƒé‡åˆ†å¸ƒèŒƒå›´ï¼š{sorted_words[-1][1]} - {sorted_words[0][1]}

**è¶‹åŠ¿æ´å¯Ÿ**ï¼š
"""

    # åˆ†æè¶‹åŠ¿
    top_words = [word for word, _ in sorted_words[:10]]
    result += f"1. **æŠ€æœ¯æ–¹å‘**ï¼šå‰10åä¸­ï¼Œ{'ç¼–ç¨‹è¯­è¨€ç±»' + str(len([w for w in top_words if w in ['Python', 'Java', 'JavaScript', 'Go', 'Rust']])) + 'ä¸ª' if any(w in ['Python', 'Java', 'JavaScript', 'Go', 'Rust'] for w in top_words) else 'ç»¼åˆæŠ€æœ¯ç±»'}\n"
    result += f"2. **å…³é”®è¯æ•°é‡**ï¼š{'è¶…è¿‡100' if len(word_freq) > 100 else f'å…±{len(word_freq)}'}ä¸ªå…³é”®è¯\n"
    result += f"3. **æƒé‡é›†ä¸­åº¦**ï¼šå‰5åå æ€»æƒé‡çš„{sum(w for _, w in sorted_words[:5]) / sum(word_freq.values()) * 100:.1f}%\n"

    result += f"""
### ğŸ’¡ ä½¿ç”¨å»ºè®®

1. **æŠ€èƒ½å­¦ä¹ **ï¼šä¼˜å…ˆå­¦ä¹ æƒé‡é«˜çš„å…³é”®è¯å¯¹åº”çš„æŠ€æœ¯æˆ–èƒ½åŠ›
2. **æ±‚èŒå‡†å¤‡**ï¼šåœ¨ç®€å†å’Œé¢è¯•ä¸­çªå‡ºè¿™äº›çƒ­é—¨æŠ€èƒ½
3. **å¸‚åœºè§‚å¯Ÿ**ï¼šå…³æ³¨æ–°å…´å…³é”®è¯ï¼ŒæŠŠæ¡è¡Œä¸šè¶‹åŠ¿
4. **ç«å“åˆ†æ**ï¼šå¯¹æ¯”ä¸åŒæ—¶æœŸè¯äº‘ï¼Œäº†è§£å¸‚åœºå˜åŒ–

---

**ğŸ“ æŸ¥çœ‹å›¾ç‰‡**ï¼šè¯äº‘å›¾å·²ä¿å­˜åˆ° `{filepath}`ï¼Œæ‚¨å¯ä»¥ä¸‹è½½æˆ–æŸ¥çœ‹ã€‚
"""

    return result


def _generate_job_wordcloud_internal(
    text_data: Optional[str] = None,
    keywords: Optional[List[Dict[str, int]]] = None,
    title: str = "å°±ä¸šå¸‚åœºçƒ­é—¨èŒä½è¯äº‘",
    max_words: int = 100,
    width: int = 1200,
    height: int = 800
) -> str:
    """
    å†…éƒ¨å‡½æ•°ï¼šç”Ÿæˆå°±ä¸šå¸‚åœºè¯äº‘å›¾ï¼ˆä¸ä½¿ç”¨@toolè£…é¥°å™¨ï¼‰

    Args:
        text_data: æ–‡æœ¬æ•°æ®ï¼Œç”¨äºæå–å…³é”®è¯ï¼ˆä»æ‹›è˜ä¿¡æ¯ã€èŒä½æè¿°ç­‰ï¼‰
        keywords: å…³é”®è¯åˆ—è¡¨ï¼Œæ ¼å¼å¦‚[{"word": "Python", "weight": 95}, {"word": "Java", "weight": 85}]
        title: è¯äº‘æ ‡é¢˜
        max_words: æœ€å¤§æ˜¾ç¤ºè¯æ•°
        width: å›¾ç‰‡å®½åº¦
        height: å›¾ç‰‡é«˜åº¦

    Returns:
        åŒ…å«è¯äº‘æ–‡ä»¶è·¯å¾„å’Œæ–‡æœ¬æè¿°çš„å­—ç¬¦ä¸²
    """
    try:
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = "assets/charts"
        os.makedirs(output_dir, exist_ok=True)

        # å¤„ç†å…³é”®è¯æ•°æ®
        if keywords:
            # ä½¿ç”¨æä¾›çš„å…³é”®è¯æƒé‡
            word_freq = {kw['word']: kw.get('weight', 1) for kw in keywords if 'word' in kw}
        elif text_data:
            # ä»æ–‡æœ¬æ•°æ®ä¸­æå–å…³é”®è¯
            word_freq = extract_keywords(text_data, max_words)
        else:
            # ä½¿ç”¨ç¤ºä¾‹æ•°æ®
            word_freq = get_sample_keywords(max_words)

        if not word_freq:
            return "âŒ æ— æ³•ç”Ÿæˆè¯äº‘ï¼šæ²¡æœ‰æä¾›æœ‰æ•ˆçš„å…³é”®è¯æ•°æ®"

        # åˆ›å»ºå›¾è¡¨
        fig, ax = plt.subplots(figsize=(14, 10))

        # ç”Ÿæˆè¯äº‘
        # å¼ºåˆ¶ä½¿ç”¨ä¸­æ–‡å­—ä½“ï¼Œç¡®ä¿ä¸­æ–‡èƒ½æ­£ç¡®æ˜¾ç¤º
        if chinese_font and os.path.exists(chinese_font):
            wordcloud = WordCloud(
                width=width,
                height=height,
                background_color='white',
                font_path=chinese_font,  # ä½¿ç”¨å®Œæ•´å­—ä½“è·¯å¾„
                max_words=max_words,
                relative_scaling=0.5,
                min_font_size=10,
                colormap='viridis',
                prefer_horizontal=0.9,  # ä¼˜å…ˆæ°´å¹³æ˜¾ç¤ºæ–‡å­—
                scale=2  # æé«˜æ¸…æ™°åº¦
            ).generate_from_frequencies(word_freq)

            # ä½¿ç”¨ç›¸åŒå­—ä½“è®¾ç½®æ ‡é¢˜
            title_font_prop = fm.FontProperties(fname=chinese_font)
            ax.set_title(title, fontsize=16, fontweight='bold', pad=20,
                        fontproperties=title_font_prop)
        else:
            # å¦‚æœæ²¡æœ‰ä¸­æ–‡å­—ä½“ï¼Œä»ç„¶ç”Ÿæˆè¯äº‘ä½†å¯èƒ½æ˜¾ç¤ºæ–¹æ¡†
            wordcloud = WordCloud(
                width=width,
                height=height,
                background_color='white',
                max_words=max_words,
                relative_scaling=0.5,
                min_font_size=10,
                colormap='viridis',
                prefer_horizontal=0.9,
                scale=2
            ).generate_from_frequencies(word_freq)
            ax.set_title(title, fontsize=16, fontweight='bold', pad=20)

        # æ˜¾ç¤ºè¯äº‘
        ax.imshow(wordcloud, interpolation='bilinear')
        ax.axis('off')
        plt.tight_layout(pad=0)

        plt.tight_layout(pad=0)

        # ä¿å­˜è¯äº‘
        # è¿‡æ»¤æ–‡ä»¶åä¸­çš„ç‰¹æ®Šå­—ç¬¦ï¼Œé¿å…ç³»ç»Ÿè§£æé”™è¯¯
        safe_title = title
        # æ›¿æ¢æˆ–ç§»é™¤ç‰¹æ®Šå­—ç¬¦
        safe_title = safe_title.replace(" ", "_")
        safe_title = safe_title.replace("-", "_")
        safe_title = safe_title.replace("/", "_")
        safe_title = safe_title.replace("\\", "_")
        safe_title = safe_title.replace(":", "_")
        safe_title = safe_title.replace("*", "_")
        safe_title = safe_title.replace("?", "_")
        safe_title = safe_title.replace('"', "_")
        safe_title = safe_title.replace("<", "_")
        safe_title = safe_title.replace(">", "_")
        safe_title = safe_title.replace("|", "_")
        # ç§»é™¤è¿ç»­çš„ä¸‹åˆ’çº¿
        safe_title = re.sub(r'_+', '_', safe_title)
        # ç§»é™¤é¦–å°¾çš„ä¸‹åˆ’çº¿
        safe_title = safe_title.strip('_')

        filename = f"{safe_title}.png"
        filepath = os.path.join(output_dir, filename)
        plt.savefig(filepath, dpi=150, bbox_inches='tight', facecolor='white')
        plt.close()

        # ç”Ÿæˆæ–‡æœ¬æè¿°
        return format_wordcloud_result(word_freq, filepath, title)

    except Exception as e:
        return f"âŒ ç”Ÿæˆè¯äº‘å¤±è´¥ï¼š{str(e)}"


# å·¥å…·å‡½æ•°ï¼šè°ƒç”¨å†…éƒ¨å‡½æ•°ç”Ÿæˆå°±ä¸šå¸‚åœºè¯äº‘
@tool
def generate_job_wordcloud(
    text_data: Optional[str] = None,
    keywords: Optional[List[Dict[str, int]]] = None,
    title: str = "å°±ä¸šå¸‚åœºçƒ­é—¨èŒä½è¯äº‘",
    max_words: int = 100,
    width: int = 1200,
    height: int = 800
) -> str:
    """
    ç”Ÿæˆå°±ä¸šå¸‚åœºè¯äº‘å›¾

    Args:
        text_data: æ–‡æœ¬æ•°æ®ï¼Œç”¨äºæå–å…³é”®è¯ï¼ˆä»æ‹›è˜ä¿¡æ¯ã€èŒä½æè¿°ç­‰ï¼‰
        keywords: å…³é”®è¯åˆ—è¡¨ï¼Œæ ¼å¼å¦‚[{"word": "Python", "weight": 95}, {"word": "Java", "weight": 85}]
        title: è¯äº‘æ ‡é¢˜
        max_words: æœ€å¤§æ˜¾ç¤ºè¯æ•°
        width: å›¾ç‰‡å®½åº¦
        height: å›¾ç‰‡é«˜åº¦

    Returns:
        åŒ…å«è¯äº‘æ–‡ä»¶è·¯å¾„å’Œæ–‡æœ¬æè¿°çš„å­—ç¬¦ä¸²
    """
    return _generate_job_wordcloud_internal(
        text_data=text_data,
        keywords=keywords,
        title=title,
        max_words=max_words,
        width=width,
        height=height
    )


@tool
def generate_skill_wordcloud(
    skills_data: Optional[List[Dict[str, int]]] = None,
    skills_text: Optional[str] = None,
    job_title: str = "æ•°æ®åˆ†æå¸ˆ"
) -> str:
    """
    ç”ŸæˆæŠ€èƒ½éœ€æ±‚è¯äº‘å›¾

    Args:
        skills_data: æŠ€èƒ½æ•°æ®ï¼Œæ ¼å¼å¦‚[{"skill": "Python", "count": 95}, {"skill": "SQL", "count": 85}]
        skills_text: æŠ€èƒ½æ–‡æœ¬æ•°æ®ï¼Œæ”¯æŒæ ¼å¼å¦‚"æ•°æ®åˆ†æ(95)ã€Python(90)ã€SQL(88)"
        job_title: èŒä½åç§°ï¼Œç”¨äºæ ‡é¢˜

    Returns:
        åŒ…å«è¯äº‘æ–‡ä»¶è·¯å¾„å’Œæ–‡æœ¬æè¿°çš„å­—ç¬¦ä¸²
    """
    if not skills_data:
        if skills_text:
            # ä»æ–‡æœ¬ä¸­è§£ææŠ€èƒ½æ•°æ®
            word_freq = parse_keyword_text(skills_text)
            skills_data = [{"skill": k, "count": v} for k, v in word_freq.items()]
        else:
            # ä½¿ç”¨ç¤ºä¾‹æ•°æ®
            skills_data = [
                {"skill": "Python", "count": 95},
                {"skill": "SQL", "count": 90},
                {"skill": "Excel", "count": 85},
                {"skill": "Tableau", "count": 70},
                {"skill": "PowerBI", "count": 65},
                {"skill": "æœºå™¨å­¦ä¹ ", "count": 60},
                {"skill": "ç»Ÿè®¡å­¦", "count": 55},
                {"skill": "æ•°æ®åˆ†æ", "count": 95},
                {"skill": "æ•°æ®å¯è§†åŒ–", "count": 70},
                {"skill": "Hadoop", "count": 50},
                {"skill": "Spark", "count": 45},
                {"skill": "Pandas", "count": 80},
                {"skill": "NumPy", "count": 75},
                {"skill": "Matplotlib", "count": 65},
                {"skill": "æ²Ÿé€šèƒ½åŠ›", "count": 60},
                {"skill": "ä¸šåŠ¡ç†è§£", "count": 70}
            ]

    # è½¬æ¢ä¸ºå…³é”®è¯æ ¼å¼
    keywords = [{"word": item['skill'], "weight": item['count']} for item in skills_data]

    # ç”Ÿæˆæ ‡é¢˜ï¼Œé¿å…é‡å¤çš„åç¼€
    if "æŠ€èƒ½éœ€æ±‚è¯äº‘" in job_title or "æŠ€èƒ½éœ€æ±‚" in job_title:
        title = job_title
    else:
        title = f"{job_title}_æŠ€èƒ½éœ€æ±‚è¯äº‘"

    return _generate_job_wordcloud_internal(
        keywords=keywords,
        title=title,
        max_words=50,
        width=1000,
        height=700
    )


@tool
def generate_company_wordcloud(
    company_data: Optional[List[Dict[str, int]]] = None,
    industry: str = "äº’è”ç½‘"
) -> str:
    """
    ç”Ÿæˆæ‹›è˜å…¬å¸è¯äº‘å›¾

    Args:
        company_data: å…¬å¸æ•°æ®ï¼Œæ ¼å¼å¦‚[{"name": "å­—èŠ‚è·³åŠ¨", "count": 120}, {"name": "è…¾è®¯", "count": 110}]
        industry: è¡Œä¸šåç§°

    Returns:
        åŒ…å«è¯äº‘æ–‡ä»¶è·¯å¾„å’Œæ–‡æœ¬æè¿°çš„å­—ç¬¦ä¸²
    """
    if not company_data:
        # ä½¿ç”¨ç¤ºä¾‹æ•°æ®
        company_data = [
            {"name": "å­—èŠ‚è·³åŠ¨", "count": 120},
            {"name": "è…¾è®¯", "count": 110},
            {"name": "é˜¿é‡Œå·´å·´", "count": 105},
            {"name": "ç¾å›¢", "count": 95},
            {"name": "äº¬ä¸œ", "count": 90},
            {"name": "ç™¾åº¦", "count": 85},
            {"name": "å°ç±³", "count": 80},
            {"name": "åä¸º", "count": 75},
            {"name": "ç½‘æ˜“", "count": 70},
            {"name": "æ‹¼å¤šå¤š", "count": 65},
            {"name": "æ»´æ»´", "count": 60},
            {"name": "å¿«æ‰‹", "count": 55},
            {"name": "Bç«™", "count": 50},
            {"name": "å°çº¢ä¹¦", "count": 45},
            {"name": "èš‚èšé›†å›¢", "count": 40}
        ]

    # è½¬æ¢ä¸ºå…³é”®è¯æ ¼å¼
    keywords = [{"word": item['name'], "weight": item['count']} for item in company_data]

    # ç”Ÿæˆæ ‡é¢˜
    title = f"{industry}è¡Œä¸š_æ‹›è˜å…¬å¸çƒ­åº¦è¯äº‘"
    return _generate_job_wordcloud_internal(
        keywords=keywords,
        title=title,
        max_words=30,
        width=1000,
        height=700
    )
